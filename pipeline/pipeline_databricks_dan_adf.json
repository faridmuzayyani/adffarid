{
	"name": "pipeline_databricks_dan_adf",
	"properties": {
		"activities": [
			{
				"name": "Copy data1",
				"type": "Copy",
				"dependsOn": [],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"source": {
						"type": "MongoDbV2Source",
						"batchSize": 100
					},
					"sink": {
						"type": "JsonSink",
						"storeSettings": {
							"type": "AzureBlobFSWriteSettings"
						},
						"formatSettings": {
							"type": "JsonWriteSettings"
						}
					},
					"enableStaging": false
				},
				"inputs": [
					{
						"referenceName": "MONGODB_hanif",
						"type": "DatasetReference",
						"parameters": {
							"collection_name": "documents"
						}
					}
				],
				"outputs": [
					{
						"referenceName": "JSON_ADLS_farid",
						"type": "DatasetReference",
						"parameters": {
							"container_name": "development",
							"folder_name": "data",
							"file_name": "documents.json"
						}
					}
				]
			},
			{
				"name": "Notebook1",
				"type": "DatabricksNotebook",
				"dependsOn": [
					{
						"activity": "Copy data1",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"notebookPath": "/Users/kelompok_5@dunialcwefdit.onmicrosoft.com/Farid/Challenge Case Day 9 : Develop Data Engineering Pipeline with Databricks and ADF/Json to Parquet"
				},
				"linkedServiceName": {
					"referenceName": "DB_Kelompok5",
					"type": "LinkedServiceReference"
				}
			}
		],
		"folder": {
			"name": "practice_case/challenge"
		},
		"annotations": []
	}
}